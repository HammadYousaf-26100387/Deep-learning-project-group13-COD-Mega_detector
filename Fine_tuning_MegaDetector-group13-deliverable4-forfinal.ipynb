{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suggested improvement: format the dataset into a suitable format for traiing the mega detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtvkhZSExGT6"
      },
      "source": [
        "IMPORTANT:\n",
        "\n",
        "Preparing the dataset in YOLO txt labels and converting it into COCO format is an absolutely essential step for the success of this project. Initially, we underestimated the complexity of this task, but after thorough exploration of the relevant GitHub repositories, we gained a better understanding of the process. We decided to create a new COCO file from scratch, rather than filtering out the existing file, as we initially considered. However, we soon realized that generating labels directly from the segment masks was not the most efficient approach. This learning has guided us towards a more refined strategy moving forward.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5lymP_uVgGU"
      },
      "source": [
        "## Preparing YOLO and MegaDetector format label files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D6XcUwMaijG",
        "outputId": "4f08c5e3-6dce-47d5-a38b-869f50369737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r /content/drive/MyDrive/dataset /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbRx_yYMw9Ta",
        "outputId": "4ae21595-f716-4c07-de0f-1afe93ea72ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ YOLO label files created.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Set updated paths\n",
        "raw_image_dir = '/content/drive/MyDrive/cod10k_filtered/train_images_unzipped/Image'\n",
        "mask_dir = '/content/drive/MyDrive/cod10k_filtered/mask_unzipped/GT_Object'\n",
        "labels_dir = '/content/drive/MyDrive/cod10k_filtered/labels'\n",
        "\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "# Optional: class index\n",
        "class_id = 0  # animal\n",
        "\n",
        "for mask_filename in os.listdir(mask_dir):\n",
        "    if not mask_filename.endswith('.png'):  # adjust extension if needed\n",
        "        continue\n",
        "\n",
        "    # Paths\n",
        "    mask_path = os.path.join(mask_dir, mask_filename)\n",
        "    image_path = os.path.join(raw_image_dir, mask_filename)\n",
        "\n",
        "    # Load mask and image\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if mask is None:\n",
        "        print(f\"[ERROR] Could not read mask: {mask_filename}\")\n",
        "        continue\n",
        "\n",
        "    height, width = mask.shape\n",
        "\n",
        "    # Find contours in mask (white regions)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    yolo_annotations = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Convert to YOLO format\n",
        "        x_center = (x + w / 2) / width\n",
        "        y_center = (y + h / 2) / height\n",
        "        norm_w = w / width\n",
        "        norm_h = h / height\n",
        "\n",
        "        yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\")\n",
        "\n",
        "    # Save .txt file with YOLO annotations\n",
        "    label_filename = os.path.splitext(mask_filename)[0] + '.txt'\n",
        "    label_path = os.path.join(labels_dir, label_filename)\n",
        "\n",
        "    with open(label_path, 'w') as f:\n",
        "        f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "print(\"✅ YOLO label files created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x67mPZTX1XBl",
        "outputId": "1abd9326-344c-4b95-a126-71aad8cb4bfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing masks:  40%|███▉      | 2090/5242 [40:06<57:34,  1.10s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Corrected Paths ===\n",
        "raw_image_dir = '/content/drive/MyDrive/cod10k_filtered/train_images_unzipped/Image'\n",
        "mask_dir = '/content/drive/MyDrive/cod10k_filtered/mask_unzipped/GT_Object'\n",
        "output_json_path = '/content/drive/MyDrive/cod10k_filtered/coco/instances.json'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(os.path.dirname(output_json_path), exist_ok=True)\n",
        "\n",
        "# === Initialize COCO Format Dictionary ===\n",
        "coco = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [\n",
        "        {\"id\": 1, \"name\": \"animal\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "annotation_id = 1\n",
        "image_id = 1\n",
        "\n",
        "# Prepare list of image filenames\n",
        "image_files = {os.path.splitext(f)[0]: f for f in os.listdir(raw_image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))}\n",
        "\n",
        "# Process each mask\n",
        "for mask_filename in tqdm(os.listdir(mask_dir), desc=\"Processing masks\"):\n",
        "    if not mask_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        continue\n",
        "\n",
        "    base_name = os.path.splitext(mask_filename)[0]\n",
        "    image_filename = image_files.get(base_name)\n",
        "\n",
        "    if not image_filename:\n",
        "        print(f\"[SKIP] No matching image for mask: {mask_filename}\")\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(raw_image_dir, image_filename)\n",
        "    mask_path = os.path.join(mask_dir, mask_filename)\n",
        "\n",
        "    # Load image and mask\n",
        "    img = cv2.imread(image_path)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"[ERROR] Could not read image: {image_filename}\")\n",
        "        continue\n",
        "    if mask is None:\n",
        "        print(f\"[ERROR] Could not read mask: {mask_filename}\")\n",
        "        continue\n",
        "    if cv2.countNonZero(mask) == 0:\n",
        "        print(f\"[SKIP] Empty mask: {mask_filename}\")\n",
        "        continue\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    # === Register image ===\n",
        "    coco[\"images\"].append({\n",
        "        \"id\": image_id,\n",
        "        \"file_name\": image_filename,\n",
        "        \"width\": width,\n",
        "        \"height\": height\n",
        "    })\n",
        "\n",
        "    # === Get contours from mask ===\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) < 10:\n",
        "            continue  # skip small blobs/noise\n",
        "\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        area = float(w * h)\n",
        "        segmentation = contour.flatten().tolist()\n",
        "\n",
        "        coco[\"annotations\"].append({\n",
        "            \"id\": annotation_id,\n",
        "            \"image_id\": image_id,\n",
        "            \"category_id\": 1,  # animal\n",
        "            \"bbox\": [float(x), float(y), float(w), float(h)],\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": 0,\n",
        "            \"segmentation\": [segmentation]\n",
        "        })\n",
        "\n",
        "        annotation_id += 1\n",
        "\n",
        "    image_id += 1\n",
        "\n",
        "# === Save COCO JSON ===\n",
        "with open(output_json_path, 'w') as f:\n",
        "    json.dump(coco, f, indent=4)\n",
        "\n",
        "print(f\"\\n✅ COCO annotations saved to: {output_json_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Fine-tuning MegaDetector",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
